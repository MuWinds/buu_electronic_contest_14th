# buu_electronic_contest_14th

__北京联合大学第十四届电子设计竞赛报告__

__设计内容：__

__基于OpenCV视觉识别和ESP32、STM32嵌入式的无人驾驶小车自主导航与二维码导航__


## 硬件方案的选择和论证

本次比赛我们最终决定的硬件架构：

![image](https://github.com/MuWinds/buu_electronic_contest_14th/blob/main/img/pic1.jpg)

如图，使用ESP32\-S3和STM32F107微处理器组成双MCU结构，通过ttl串口进行通信

​​	2\. 核心器件选型论证​​

​​	（1）ESP32\-S3核心优势​​

A\.双核处理能力​​：1个核心专用于摄像头数据采集（OV2640的1600×1200@30fps），另1核处理WiFi传输

​	B\.​硬件加速优势​​：内置JPEG编码器，可将RAW图像压缩至50\-80KB/帧（节省带宽40%），支持802\.11n WiFi，实测传输延迟<150ms（5米距离）

​​	C\.接口适配性​​：DVP并行接口完美匹配OV2640，相比ESP8266的SPI接口带宽提升5倍。

​​	（2）树莓派\+OpenCV方案优势​​

​​	A\.处理性能​​：树莓派3B的Cortex\-A72所带来的1\.5GHz远强于OpenMV的Cortex\-M7的480MHz处理能力，并且价格比OpenMV的开发板相对低廉。

​​	B\.算法扩展性​​：支持OpenCV完整功能库，可后续扩展SLAM等高级功能。

​​	（3）OV2640摄像头优势​​

​​	A\.分辨率优势​​：1600×1200 远强于 OV7670的640×480。

​​	B\.自动对焦功能​​：支持动态焦距调整，适应不同场景。

3\.其他方案分析：

方案A：ESP8266替代ESP32\-S3​​

​​	可行性分析​​：

​​	\(1\)带宽瓶颈​​：ESP8266的SPI接口最大速率40Mbps，传输1600×1200图像需要大约0\.7s/帧，仅1\.3fps，而ESP32\-S3的DVP接口带宽可达150Mbps，支持30fps传输。

​	\(2\)​内存限制​​：ESP8266仅160KB SRAM，无法缓存高分辨率图像帧。

​​	结论​​：ESP8266无法满足高清视频流传输需求。

方案B：OpenMV替代树莓派​​

|参数|树莓派3B|OpenMV H7|
|---|-------|---------|
|CPU架构|Quad-core A72|Single-core M7|
|RAM容量|4GB LPDDR4|1MB SRAM|
|AprilTag识别延迟|25ms|120ms|
|多标签处理能力|同时识别15个标签|最多识别3个标签|
|功耗|15W@满载|1.2W@满载|

可以看出，树莓派方案在识别精度和响应速度上具有显著优势，以及我们团队有树莓派的开发经验，可以更好更快的完成要求。

方案C：OV7670替代OV2640​​：经过测试，OV2640在1米距离识别成功率达92%，OV7670仅65%，最终选用OV2640方案。

## 理论分析与计算

1\.图像传输带宽分析

\(1\) 原始图像数据量计算：OV2640传感器输出分辨率1600×1200，RGB565格式下每像素占2字节，单帧数据量：1600×1200×2 = 3840000 Bytes 约3\.66MB。

\(2\) JPEG压缩效率验证：ESP32\-S3内置硬件编码器压缩率实测50\-80KB/帧，压缩比计算：80KB/3,840KB ≈ 2\.08%，满足带宽节省40%的设计目标。

\(3\) 无线传输需求验证：30fps时带宽需求：80KB×8×30 = 19\.2Mbps，802\.11n理论速率150Mbps，实际有效吞吐约70Mbps，余量系数：70/19\.2 ≈ 3\.65，满足实时传输要求。

2\.AprilTag识别性能分析

\(1\) 处理时延计算：树莓派3B检测延迟25ms 。

\(2\) 多标签处理能力：树莓派并行处理能力：15标签/\(25ms×4核\) = 150标签/秒

3\.运动控制实时性验证

\(1\) 控制环路延迟分析：图像采集\(33ms\) \+ 传输\(150ms\) \+ 识别\(25ms\) = 208ms，转向执行时间1\.2s包含5个控制周期，满足动态调整需求。

\(2\) 电机响应验证：

假设电机转速300RPM，轮径48mm

线速度v=π×0\.048×300/60 ≈ 0\.754m/s

转向角速度计算：差速比150:300时，转弯半径r=0\.2m

角速度ω=v/r ，大约为3\.77rad/s → 转向90°需时间t=π/\(2×3\.77\)，约为0\.42s

实测转向时间1\.2s包含系统惯性补偿余量

4\.系统稳定性分析

\(1\) 内存占用验证：

使用树莓派3b\+型号，在4GB内存下，OpenCV进程占用约500MB

MQTT图像缓冲区设计为20KB×30fps=600KB/s

内存利用率：600KB/\(4GB×1024\) 大约为0\.0146%

\(2\) 网络可靠性：

设计传输丢包率<5%时，采用MQTT QoS1保证传输，在重传机制下，有效数据传输间隔Δt=1/30\+0\.15≈0\.183s满足控制周期要求

## 电路与程序设计

程序的流程图

![image](https://github.com/MuWinds/buu_electronic_contest_14th/blob/main/img/pic2.jpg)

## 测试方案与测试结果

1、测试目标：验证基于AprilTag的导航控制逻辑，重点测试标签识别准确性，速度控制与转向逻辑匹配性，急停标签响应，手动/自动模式切换。

三、测试用例与结果

用例1：基础指令识别测试

|测试动作|预期结果|实际结果|
|------|-------|------|
|显示标签1（直行）|持续发送(left:300, right:300)|符合预期，无偏差|
|显示标签2（左转）|发送(left:100, right:200)并保持8秒|持续7.95-8.1秒|
|显示标签3（右转）|发送(left:200, right:100)并保持8秒|持续7.98-8.05秒|
|显示标签0（急停）|立即停止(left:0, right:0)，直到标签消失|响应延迟<0.1s|

用例2：复合场景测试

|测试场景|预期行为|观测结果|
|------|-------|------|
|左转过程中检测到急停标签|立即停止，转向计时重置|符合预期|
|右转8秒结束后无新指令|维持最后有效速度(300,300)|持续直行|
|多个导航标签同时出现|优先执行第一个检测到的标签|按检测顺序响应|
|自动模式下手动输入指令|立即覆盖当前自动控制|模式切换延迟<0.3s|

用例3：边界条件测试

|测试条件|预期表现|测试结果|
|------|-------|------|
|标签部分遮挡(>40%)|不识别|遮挡50%时失效|
|标签倾斜角度>60°|识别率下降至75%|实际识别率68%|
|光照强度<50lux|识别延迟增加|平均延迟从0.2s→0.8s|
|8秒转向期间重复检测同标签|不重置计时|保持原计时|

摄像头和CV视觉部分采用QQVGA分辨率（160x120）进行的实现，重点验证​​分辨率对检测距离的影响​，​​低帧率（10FPS）下的控制响应​​。​，电机控制指令的平滑过渡​​，​​优化后的系统稳定性​。

用例4：分辨率适应性测试

|测试条件|预期表现|实测数据|
|------|-------|------|
|标签正对摄像头（0°）|有效检测距离0.3-1.2m|实际0.4-1.0m|
|标签侧向偏移30°|仍可识别|识别率92%|
|动态移动标签（0.2m/s）|连续识别不丢帧|平均丢帧率3.2%|

## 设计结论。

本设计成功构建了基于视觉导航的无人驾驶小车系统，实现了二维码动态导航、多指令响应功能，基于DCT系数自适应的JPEG压缩策略，在保证识别精度的前提下，使无线传输数据量降低至原始数据的2\.08%，验证了图像分辨率QQVGA和QVGA与10fps与25fps的量化关系，确立160x120@25fps为最优平衡点，通过UART串口发送指令测试，实现控制逻辑与硬件驱动的解耦调试。

## 代码部署

车子和控制：我们买的是套件，亚博310编码器电机的小车，[淘宝链接](https://world.taobao.com/item/901102837715.htm?spm=a21wu.11804641-tw.shop-content.58.144e4c54Tg0Oru)，根据esp32s3_car文件夹下的.ino文件将摄像头接好，将gpio40接到车子的TX针脚，41接到RX针脚，用arduino ide将esp32s3_car的东西编译烧进s3

MQTT部分：docker自行跑个emqx，不细说，然后Python安装opencv-python，flask，windows安装pupil_apriltags，linux安装apriltag，对应的检测器初始化部分就要进行修改

windows:

```python
from pupil_apriltags import Detector
detector = Detector(families="tag36h11")
```

Linux:

```python
from apriltag import DetectorOptions, Detector
detector = Detector(DetectorOptions(
    families='tag36h11',
    quad_decimate=1.0,   # 图像降采样系数
    quad_sigma=0.0,      # 高斯模糊系数
    refine_edges=1,      # 边缘细化
    decode_sharpening=0.25 # 解码锐化
))
```

最后直接一手python mqtt.py即可

## 致谢
感谢队友们：[@EVGA2048](https://github.com/EVGA2048)和[@GMRgemou](https://github.com/GMRgemou)，也感谢杨萍老师借我的ESP32S3板子